#!/bin/python3
#script by frenzis

from bs4 import BeautifulSoup, Comment
from urllib.request import Request, urlopen
from urllib.parse import urlparse
import re
import sys


i = 1
links = []
text = []
remote = []
local = []
com = []
pat = []
l = False
c = False
savefile = False
word = "a"
################################################################################
# Argument test
################################################################################
if len(sys.argv) == 1:
    print("Usage:", sys.argv[0], "[-u website address] OPTIONS:  [-w word] [-s savefile] ")
    print("Type", sys.argv[0], "--help for more information")
    sys.exit()
else:
    n = len(sys.argv)
#####Start Script
print(r"""
                        ___                   _
/ / /\ \ \___| |__     / __\ __ __ ___      _| | ___ _ __
\ \/  \/ / _ \ '_ \   / / | '__/ _` \ \ /\ / / |/ _ \ '__|
 \  /\  /  __/ |_) | / /__| | | (_| |\ V  V /| |  __/ |
  \/  \/ \___|_.__/  \____/_|  \__,_| \_/\_/ |_|\___|_|  v0.2


""")
################################################################################

def help():
    print("Usage:", sys.argv[0], "[-u website address] OPTIONS:  [-w word] [-s savefile] \n")
    print("-u           website address, format http://www.example.com ")
    print("-w           specific word to find, default web links")
    print("-s           save results to a file")
    sys.exit()
################################################################################
# save report
################################################################################
def save_report(savefile):

    file = open(savefile, "w+")
    if l :
        file.write("\nLocal links:\n \n")
        for element in local:
            file.write(str(element+"\n"))
        file.write("\nRemote links:\n \n")
        for element in remote:
            file.write(str(element+"\n"))

    if word != 'a' :
        file.write("\nWanted word is in here:\n \n")
        for element in pat:
            file.write(str(element+"\n"))
    if c :
        file.write("\nComments:\n \n")
        for element in com:
            file.write(str(element+"\n"))

    file.close()
################################################################################
# Links finder
################################################################################

def links_finder(req,c,l,word,savefile):
    i = 1
    index = 0
    website = urlparse(req).netloc
    if l:
        for link in soup.findAll('a'):
            links.append(link.get("href"))
            if (links[index] == "#" or links[index] == ''):
                links[index] = ""
            index += 1

        while("" in links):
            links.remove("")
        total = len(links) - 1

###############filter for local or remote links

        while total > i:
            if (links[i][0] == "h" or links[i][0] == "w"):
                find = re.findall( str(website), links[i])
                if find:
                    local.append(links[i])
                else:
                    remote.append(links[i])
            i += 1

        print(r"""

                Local links:

        """)
        for n in local:
            print(n)

        print(r"""

            Remote links:

        """)
        for n in remote:
            print(n)

    if c:
        comments(savefile)
    elif savefile:
        save_report(savefile)
    else:
        sys.exit()

################################################################################
# word/pattern finder
################################################################################
def pattern_finder(addr,c,l,word,savefile):
    i = 0
    index = 0

    soup_str = str(soup)

    f = open("report.txt","w+")
    f.write(soup_str+'/n')
    f.close()
    f = open("report.txt", "r")
    content = f.read()
    list = content.split()

    while(" " in list):
        list.remove("")

    for n in list:          #check number of lines
        if n:
            i += 1

    print(r"""

            Pattern:

    """)

    for pattern in list:
        find = re.findall(word,pattern)
        if find:
            print(pattern)
            pat.append(pattern)

    f.close()

    if l:
        links_finder(addr,c,l,word)
    elif c:
        comments(savefile)
    elif savefile:
        save_report(savefile)
    else:
        sys.exit()

################################################################################
# comment finder <!--
################################################################################
def comments(savefile):

    print(r"""

            Comments:

    """)
    for comments in soup.findAll(text=lambda text:isinstance(text, Comment)):
        com.append(comments)
        print(comments)
        comments.extract()

    if savefile :
        save_report(savefile)

    sys.exit()

################################################################################

for flags in sys.argv:
    if (sys.argv[i] == "--help"):
        help()

while n > i:
    if (sys.argv[i] == "-u"):
        addr = sys.argv[i+1]
    elif (sys.argv[i] == "-w"):
        word = sys.argv[i+1]
    elif (sys.argv[i] == "-s"):
        savefile = sys.argv[i+1]
    elif (sys.argv[i] == "-c"):
        c = True
    elif (sys.argv[i] == "-l"):
        l = True
    i += 1

html_page = urlopen(addr)
html_doc = html_page.read()
html_page.close()
soup = BeautifulSoup(html_doc, "html.parser")

if l :
    links_finder(addr,c,l,word,savefile)
elif word != "a" :
    pattern_finder(addr,c,l,word,savefile)
elif c :
    comments(savefile)
